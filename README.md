# State-of-the-art of Under Display Camera Image Restoration

### LAST UPDATE: 06th October 2020

This repository provides state-of-the-art (SoTA) papers and results for Under Display Camera (UDC). We do our best to keep this repository up to date.  If you do find a problem's SoTA result is out of date or missing, please raise this as an issue (with this information: research paper name, dataset, metric, source code and year). We will fix it immediately.

Please note that this repo is the very first repo in this field, and UDC is early-merging topics so the content will not very much.
## Papers

* _Image Restoration for Under-Display Camera [[Project]](https://yzhouas.github.io/projects/UDC/udc.html) [[paper]](https://arxiv.org/pdf/2003.04857v1.pdf)
* _Deep Atrous Guided Filter for Image Restoration in Under Display Cameras [[paper]](https://arxiv.org/pdf/2008.06229v2.pdf) [[code]](https://github.com/varun19299/deep-atrous-guided-filter)

## Challenges
* _Real-world Computer Vision from Inputs with Limited Quality [[RLG]](https://rlq-tod.github.io/index.html)



<!-- #### 2. Machine Translation

<table>
  <tbody>
    <tr>
      <th width="30%">Research Paper</th>
      <th align="center" width="20%">Datasets</th>
      <th align="center" width="20%">Metric</th>
      <th align="center" width="20%">Source Code</th>
      <th align="center" width="10%">Year</th>
    </tr>
    <tr>
      <td><a href='https://arxiv.org/pdf/1808.09381v2.pdf'> Understanding Back-Translation at Scale </a></td>
      <td align="left"> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>
      <td align="left"> <ul><li>  BLEU: 45.6 </li><li>   BLEU: 35.0 </li></ul> </td>
      <td align="left"> <ul><li><a href='https://github.com/pytorch/fairseq'>PyTorch</a></li></ul></td>
      <td align="left">2018</td>    
    </tr>
    <tr>
      <td><a href='https://arxiv.org/pdf/1711.02132.pdf'>WEIGHTED TRANSFORMER NETWORK FOR
MACHINE TRANSLATION</a></td>
      <td align="left"> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>
      <td align="left"> <ul><li>  BLEU: 41.4 </li><li>   BLEU: 28.9 </li></ul> </td>
      <td align="left"> <ul><li><a href=''>NOT FOUND</a></li></ul></td>
      <td align="left">2017</td>    
    </tr>
    <tr>
      <td><a href='https://arxiv.org/abs/1706.03762'>Attention Is All You Need</a></td>
      <td align="left"> <ul><li>WMT 2014 English-to-French </li><li>WMT 2014 English-to-German </li></ul></td>
      <td align="left"> <ul><li>  BLEU: 41.0 </li><li>   BLEU: 28.4 </li></ul> </td>
      <td align="left"> <ul><li><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch'>PyTorch</a> </li><li> <a href='https://github.com/tensorflow/tensor2tensor'>Tensorflow</a></li></ul></td>
      <td align="left">2017</td>    
    </tr>
     <tr>
      <td><a href='https://einstein.ai/static/images/pages/research/non-autoregressive-neural-mt.pdf'>NON-AUTOREGRESSIVE
NEURAL MACHINE TRANSLATION</a></td>
      <td align="left"> <ul><li> WMT16 Roâ†’En </li></ul></td>
      <td align="left"> <ul><li> BLEU: 31.44 </li></ul> </td>
      <td align="left"><ul><li><a href='https://github.com/salesforce/nonauto-nmt'>PyTorch</a></ul></li></td>
      <td align="left">2017</td>    
      </tr>
          <tr>
      <td><a href='https://arxiv.org/abs/1703.04887'> Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets</a></td>
      <td align="left"> <ul><li>NIST02    </li><li>NIST03 </li><li>NIST04 </li><li>NIST05 </li></ul></td>
      <td align="left"><li>38.74  </li><li>36.01  </li><li> 37.54 </li><li>33.76 </li></ul </td>
      <td align="left"> <ul><li><a href='https://github.com/ngohoanhkhoa/GAN-NMT'>NMTPY</a> </li></ul></td>
      <td align="left">2017</td>    
    </tr>
  </tbody>
</table>   -->

Email: vovantu.hust@gmail.com
